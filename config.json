{
    "n_epochs": 2500,
    "batch_size": 12,
    "batch_size_granularity": 128,
    "n_input_dims": 2,
    "n_output_dims": 3,

    "loss": "RelativeL2",
	"optimizer": "Adam",
    "learning_rate": 1e-2,

    "n_levels": 16,
    "n_features_per_level": 2,
    "log2_hashmap_size": 16,
    "base_resolution": 16,
    "per_level_scale": 1.5,

    "activation": "ReLU",
    "n_neurons": 64,
    "n_hidden_layers": 2,
    "n_output": 16
}
